{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [1. Introduction](#1.-Introduction)\n",
    "\t* [1.1 What is an OpenAI gym environment object?](#1.1-What-is-an-OpenAI-gym-environment-object?)\n",
    "\t\t* [1.1.1 Methods:](#1.1.1-Methods:)\n",
    "\t\t* [1.1.2 Attributes:](#1.1.2-Attributes:)\n",
    "\t* [1.2 Useful Links](#1.2-Useful-Links)\n",
    "* [2. Environement Examples](#2.-Environement-Examples)\n",
    "\t* [2.1 Algorithms: Copy-v0](#2.1-Algorithms:-Copy-v0)\n",
    "\t\t* [2.1.1 A heuristic solve!](#2.1.1-A-heuristic-solve!)\n",
    "\t* [2.2 Atari: Breakout-v0](#2.2-Atari:-Breakout-v0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a practical introduction to OpenAI Gym Environments. You can find a list of the environments here:\n",
    "* https://gym.openai.com/envs/\n",
    "\n",
    "The code for them is located in `../gym/envs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 What is an OpenAI gym environment object?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially it is just an object that has some standard methods and attributes\n",
    "\n",
    "`env = gym.make('Name_of_registered_environment')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `env.reset()` - starts the environment, may return an initial state\n",
    "2. `env.render()` - return a visual representation of the state\n",
    "    * Often has an argument `mode` which can take on values:\n",
    "        * env.render(mode='human')\n",
    "        * env.render(mode='rgb_array')\n",
    "3. `env.step(some_action)` - submit an action to the environment. Returns a tuple:\n",
    "    * (observation, reward, done, info)\n",
    "        * observation: new state\n",
    "        * reward: ...\n",
    "        * done: if game is episodic, is it finished\n",
    "        * info: diagnostic information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Attributes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `env.action_space` - a space object containing valid actions.\n",
    "2. `env.observation_space` - a space object containing valid states. \n",
    "    * These space objects have some useful methods/attributes themselves:\n",
    "        * `space.sample()` - return a random sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Useful Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://gym.openai.com/docs/\n",
    "* https://gym.openai.com/envs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Environement Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Algorithms: Copy-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Copy-v0')\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 A heuristic solve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()  # initial state returned by reset\n",
    "env.render()\n",
    "while obs < 5:  # 5 is the null return\n",
    "    obs, reward, done, _ = env.step((1, 1, obs))\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Atari: Breakout-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Breakout-v0')\n",
    "state = env.reset()\n",
    "# env.render()  # haven't quite worked out how to get this to work within notebook\n",
    "                # it will work outside the notebook when call has access to screen\n",
    "plt.imshow(env.render(mode='rgb_array'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space, env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "state = env.reset()\n",
    "for t in range(100):\n",
    "    ax.imshow(state)\n",
    "    display.display(fig)\n",
    "    display.clear_output(wait=True)\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box2D: CarRacing-v0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haven't got this one to work inside the notebook yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v0')\n",
    "# state = env.reset()\n",
    "# env.render()  # haven't quite worked out how to get this to work within notebook\n",
    "                # it will work outside the notebook when call has access to screen\n",
    "# env.render(mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
